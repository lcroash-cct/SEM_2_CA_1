{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERT screenshots and/or terminal output to demonstrate the process of activating the hadoop cluster\n",
    "# then adding the files to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hduser/env/myenv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/usr/local/hadoop/bin:/bin:/usr/local/hadoop/sbin:/usr/local/hadoop/bin:/bin:/usr/local/hadoop/sbin:/opt/spark/bin:/usr/local/hadoop/bin:/bin:/usr/local/hadoop/sbin:/opt/spark/bin\n",
      "/home/hduser/env/myenv/bin/python\n",
      "/home/hduser/env/myenv\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "import findspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# os.environ['SPARK_HOME']\n",
    "\n",
    "# os.environ['SPARK_HOME'] = '/opt/spark/'\n",
    "\n",
    "print(os.environ['PATH'])\n",
    "\n",
    "findspark.init('/opt/spark/')\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkExample').config('spark.driver.python', '/snap/jupyter/6/bin/python3').getOrCreate()\n",
    "\n",
    "import sys\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfs = spark.read.csv(\"hdfs://localhost:9000/transactions/*.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+---------+--------+-----+----------+------------+------------+------------+------------+--------------+-----+-----+---------------+-----------+--------------------+-----------+--------------------+----------+------------+------------+\n",
      "|      _c0|      _c1|         _c2|      _c3|     _c4|  _c5|       _c6|         _c7|         _c8|         _c9|        _c10|          _c11| _c12| _c13|           _c14|       _c15|                _c16|       _c17|                _c18|      _c19|        _c20|        _c21|\n",
      "+---------+---------+------------+---------+--------+-----+----------+------------+------------+------------+------------+--------------+-----+-----+---------------+-----------+--------------------+-----------+--------------------+----------+------------+------------+\n",
      "|SHOP_WEEK|SHOP_DATE|SHOP_WEEKDAY|SHOP_HOUR|QUANTITY|SPEND| PROD_CODE|PROD_CODE_10|PROD_CODE_20|PROD_CODE_30|PROD_CODE_40|     CUST_CODE|seg_1|seg_2|      BASKET_ID|BASKET_SIZE|BASKET_PRICE_SENS...|BASKET_TYPE|BASKET_DOMINANT_M...|STORE_CODE|STORE_FORMAT|STORE_REGION|\n",
      "|   200643| 20061224|           1|       14|       1| 1.77|PRD0900008|     CL00042|    DEP00011|      G00004|      D00002|CUST0000096000|   AZ|   BU|994103700265943|          M|                  UM| Small Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061218|           2|       19|       1| 1.05|PRD0900011|     CL00033|    DEP00008|      G00004|      D00002|CUST0000206560|   BG|   DI|994103700348637|          L|                  UM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061223|           7|       18|       3| 3.15|PRD0900011|     CL00033|    DEP00008|      G00004|      D00002|CUST0000017325|   CT|   AT|994103700207109|          L|                  MM|     Top Up|               Fresh|STORE00001|          LS|         E02|\n",
      "|   200643| 20061223|           7|       15|       1| 1.03|PRD0900015|     CL00015|    DEP00004|      G00003|      D00001|CUST0000871730|   BG| null|994103700845926|          L|                  UM|     Top Up|               Fresh|STORE00001|          LS|         E02|\n",
      "|   200643| 20061218|           2|       15|       3|13.26|PRD0900016|     CL00165|    DEP00055|      G00016|      D00003|CUST0000173993|   BG|   CZ|994103700324145|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061219|           3|       12|       3|13.26|PRD0900016|     CL00165|    DEP00055|      G00016|      D00003|CUST0000540040|   CT|   AT|994103700597782|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061219|           3|       15|       3|13.26|PRD0900016|     CL00165|    DEP00055|      G00016|      D00003|CUST0000017325|   CT|   AT|994103700207110|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061218|           2|       15|       3| 2.55|PRD0900020|     CL00202|    DEP00067|      G00021|      D00005|CUST0000173993|   BG|   CZ|994103700324145|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061224|           1|       19|       1| 0.85|PRD0900020|     CL00202|    DEP00067|      G00021|      D00005|          null| null| null|994103700017507|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061223|           7|       15|       1| 0.52|PRD0900024|     CL00160|    DEP00054|      G00016|      D00003|CUST0000871730|   BG| null|994103700845926|          L|                  UM|     Top Up|               Fresh|STORE00001|          LS|         E02|\n",
      "|   200643| 20061222|           6|       12|       1| 0.52|PRD0900024|     CL00160|    DEP00054|      G00016|      D00003|CUST0000160899|   BG|   EQ|994103700314386|          L|                  MM|     Top Up|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061222|           6|        8|       3| 2.52|PRD0900034|     CL00129|    DEP00046|      G00013|      D00003|CUST0000534768|   AZ|   DI|994103700593728|          L|                  LA|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061219|           3|       21|       1| 1.56|PRD0900049|     CL00160|    DEP00054|      G00016|      D00003|CUST0000436394|   AZ| null|994103700520900|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061218|           2|       13|       1| 1.75|PRD0900058|     CL00020|    DEP00005|      G00003|      D00001|CUST0000344309|   CT|   AT|994103700451904|          L|                  UM|  Full Shop|             Grocery|STORE00001|          LS|         E02|\n",
      "|   200643| 20061224|           1|       16|       1| 2.14|PRD0900063|     CL00185|    DEP00062|      G00018|      D00004|          null| null| null|994103700081186|          L|                  MM|     Top Up|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061222|           6|       15|       1| 1.09|PRD0900066|     CL00041|    DEP00011|      G00004|      D00002|CUST0000414514|   CT|   BU|994103700504485|          L|                  UM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061221|           5|        8|       1| 0.57|PRD0900069|     CL00134|    DEP00047|      G00013|      D00003|CUST0000622502|   AZ|   CZ|994103700659723|          L|                  MM|     Top Up|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061218|           2|       12|       1| 1.05|PRD0900077|     CL00150|    DEP00052|      G00015|      D00003|CUST0000710863|   AZ|   DI|994103700726239|          L|                  MM|  Full Shop|               Mixed|STORE00001|          LS|         E02|\n",
      "|   200643| 20061224|           1|       14|       1| 1.07|PRD0900079|     CL00157|    DEP00053|      G00016|      D00003|          null| null| null|994103700150926|          L|                  LA|     Top Up|               Mixed|STORE00001|          LS|         E02|\n",
      "+---------+---------+------------+---------+--------+-----+----------+------------+------------+------------+------------+--------------+-----+-----+---------------+-----------+--------------------+-----------+--------------------+----------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SHOP_WEEK: string (nullable = true)\n",
      " |-- SHOP_DATE: string (nullable = true)\n",
      " |-- SHOP_WEEKDAY: string (nullable = true)\n",
      " |-- SHOP_HOUR: string (nullable = true)\n",
      " |-- QUANTITY: string (nullable = true)\n",
      " |-- SPEND: string (nullable = true)\n",
      " |-- PROD_CODE: string (nullable = true)\n",
      " |-- PROD_CODE_10: string (nullable = true)\n",
      " |-- PROD_CODE_20: string (nullable = true)\n",
      " |-- PROD_CODE_30: string (nullable = true)\n",
      " |-- PROD_CODE_40: string (nullable = true)\n",
      " |-- CUST_CODE: string (nullable = true)\n",
      " |-- seg_1: string (nullable = true)\n",
      " |-- seg_2: string (nullable = true)\n",
      " |-- BASKET_ID: string (nullable = true)\n",
      " |-- BASKET_SIZE: string (nullable = true)\n",
      " |-- BASKET_PRICE_SENSITIVITY: string (nullable = true)\n",
      " |-- BASKET_TYPE: string (nullable = true)\n",
      " |-- BASKET_DOMINANT_MISSION: string (nullable = true)\n",
      " |-- STORE_CODE: string (nullable = true)\n",
      " |-- STORE_FORMAT: string (nullable = true)\n",
      " |-- STORE_REGION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform groupby operations to aggregate data by date for:\n",
    "##### total spend by store code\n",
    "##### total spend by store format\n",
    "##### total spend by prod code / prod_code_10 / prod_code_20 etc - depending on the highest level of granularity during EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.createOrReplaceTempView(\"STORE_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 06:56:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 06:56:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+---------+-----------+\n",
      "| 20061223|STORE00003|    215.0|     316.65|\n",
      "| 20061219|STORE00113|    235.0|     340.55|\n",
      "| 20061221|STORE00120|     21.0|      70.53|\n",
      "| 20061224|STORE00227|     73.0|     164.17|\n",
      "| 20061224|STORE00432|     86.0|     118.75|\n",
      "| 20061219|STORE00494|     13.0|      10.78|\n",
      "| 20061221|STORE00633|    144.0|     228.09|\n",
      "| 20061221|STORE00639|    155.0|      178.8|\n",
      "| 20061222|STORE01091|      9.0|      12.73|\n",
      "| 20061220|STORE01215|    125.0|     202.03|\n",
      "| 20061218|STORE01289|     36.0|      37.31|\n",
      "| 20061222|STORE01330|     24.0|      22.07|\n",
      "| 20061222|STORE01603|     21.0|       27.4|\n",
      "| 20061224|STORE01651|    113.0|     137.57|\n",
      "| 20061222|STORE01672|     41.0|      53.55|\n",
      "| 20061221|STORE01707|    264.0|     350.76|\n",
      "| 20061223|STORE01793|     23.0|      18.85|\n",
      "| 20061223|STORE02524|    147.0|     200.77|\n",
      "| 20061219|STORE02575|      8.0|      28.24|\n",
      "| 20061220|STORE02619|    241.0|     316.43|\n",
      "+---------+----------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "store_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_format_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, STORE_FORMAT, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE, STORE_FORMAT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 06:58:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, STORE_CODE, STORE_FORMAT\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE, STORE_FORMAT\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 06:58:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE, STORE_FORMAT\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|STORE_FORMAT|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "| 20061218|STORE00107|          LS|     98.0|     153.96|\n",
      "| 20061218|STORE00120|          MS|      8.0|      22.61|\n",
      "| 20061218|STORE00422|          MS|     78.0|     147.67|\n",
      "| 20061221|STORE00425|          MS|     63.0|     118.09|\n",
      "| 20061221|STORE00460|          LS|    217.0|     317.46|\n",
      "| 20061221|STORE00807|          LS|     66.0|      79.44|\n",
      "| 20061222|STORE00840|          LS|    325.0|     487.22|\n",
      "| 20061221|STORE00877|          LS|    290.0|     487.31|\n",
      "| 20061223|STORE00895|          SS|      6.0|       8.73|\n",
      "| 20061222|STORE00966|          MS|    145.0|     194.21|\n",
      "| 20061218|STORE01035|          LS|     16.0|      16.61|\n",
      "| 20061219|STORE01160|          LS|    108.0|     136.29|\n",
      "| 20061224|STORE01298|          SS|     26.0|      26.28|\n",
      "| 20061221|STORE01316|          LS|    245.0|     429.21|\n",
      "| 20061221|STORE01501|          MS|     90.0|     113.72|\n",
      "| 20061218|STORE01535|          SS|      3.0|       2.27|\n",
      "| 20061220|STORE01650|          SS|     31.0|      81.67|\n",
      "| 20061223|STORE01695|          LS|    224.0|     483.26|\n",
      "| 20061219|STORE01984|          SS|      3.0|       2.21|\n",
      "| 20061218|STORE02192|          SS|      5.0|       4.71|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "store_format_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_10_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, PROD_CODE_10, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE, PROD_CODE_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:03:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_10, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_10, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:03:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_10, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|PROD_CODE_10|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "| 20060410|STORE00001|     CL00012|      1.0|       0.01|\n",
      "| 20060410|STORE00001|     CL00020|      5.0|        2.2|\n",
      "| 20060410|STORE00001|     CL00201|      1.0|       0.81|\n",
      "| 20060410|STORE00002|     CL00001|      2.0|       1.72|\n",
      "| 20060410|STORE00003|     CL00023|      1.0|       1.93|\n",
      "| 20060410|STORE00003|     CL00065|      1.0|       1.16|\n",
      "| 20060410|STORE00003|     CL00074|      2.0|       5.22|\n",
      "| 20060410|STORE00003|     CL00128|      1.0|       1.02|\n",
      "| 20060410|STORE00003|     CL00135|      1.0|       0.16|\n",
      "| 20060410|STORE00003|     CL00157|      2.0|       1.58|\n",
      "| 20060410|STORE00003|     CL00161|      3.0|        3.3|\n",
      "| 20060410|STORE00004|     CL00017|      1.0|       3.35|\n",
      "| 20060410|STORE00004|     CL00043|      1.0|       0.97|\n",
      "| 20060410|STORE00004|     CL00063|      6.0|       6.64|\n",
      "| 20060410|STORE00004|     CL00070|      3.0|       0.84|\n",
      "| 20060410|STORE00004|     CL00083|      3.0|       6.42|\n",
      "| 20060410|STORE00004|     CL00128|      1.0|        0.9|\n",
      "| 20060410|STORE00004|     CL00159|      2.0|       1.94|\n",
      "| 20060410|STORE00006|     CL00068|      1.0|       2.19|\n",
      "| 20060410|STORE00006|     CL00090|      3.0|       8.64|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prod_10_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_20_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, PROD_CODE_20, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE, PROD_CODE_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:05:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_20, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_20, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:05:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_20, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|PROD_CODE_20|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "| 20060410|STORE00001|    DEP00003|      1.0|       0.01|\n",
      "| 20060410|STORE00001|    DEP00005|      5.0|        2.2|\n",
      "| 20060410|STORE00001|    DEP00025|      3.0|       2.61|\n",
      "| 20060410|STORE00001|    DEP00051|      3.0|       3.97|\n",
      "| 20060410|STORE00001|    DEP00067|      1.0|       0.81|\n",
      "| 20060410|STORE00001|    DEP00070|      1.0|       0.67|\n",
      "| 20060410|STORE00002|    DEP00008|      2.0|       2.21|\n",
      "| 20060410|STORE00002|    DEP00011|      1.0|        0.4|\n",
      "| 20060410|STORE00003|    DEP00008|     13.0|      17.66|\n",
      "| 20060410|STORE00003|    DEP00016|      1.0|       5.14|\n",
      "| 20060410|STORE00003|    DEP00021|     11.0|      16.59|\n",
      "| 20060410|STORE00003|    DEP00025|      4.0|       4.83|\n",
      "| 20060410|STORE00003|    DEP00069|      1.0|       1.87|\n",
      "| 20060410|STORE00003|    DEP00073|      3.0|       1.87|\n",
      "| 20060410|STORE00003|    DEP00083|      1.0|       6.26|\n",
      "| 20060410|STORE00004|    DEP00008|      4.0|       5.88|\n",
      "| 20060410|STORE00004|    DEP00010|      1.0|       0.43|\n",
      "| 20060410|STORE00004|    DEP00013|      2.0|      20.99|\n",
      "| 20060410|STORE00004|    DEP00021|      3.0|       5.21|\n",
      "| 20060410|STORE00004|    DEP00022|      4.0|       4.62|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prod_20_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_30_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, PROD_CODE_30, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE, PROD_CODE_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:07:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_30, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_30, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:07:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_30, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|PROD_CODE_30|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "| 20060410|STORE00001|      G00002|      1.0|       0.01|\n",
      "| 20060410|STORE00001|      G00003|      5.0|        2.2|\n",
      "| 20060410|STORE00001|      G00006|      1.0|       2.58|\n",
      "| 20060410|STORE00001|      G00010|      3.0|       1.02|\n",
      "| 20060410|STORE00001|      G00015|      4.0|       5.26|\n",
      "| 20060410|STORE00002|      G00003|      1.0|       2.05|\n",
      "| 20060410|STORE00002|      G00011|      1.0|       0.41|\n",
      "| 20060410|STORE00002|      G00016|      3.0|       3.64|\n",
      "| 20060410|STORE00002|      G00021|      1.0|        1.4|\n",
      "| 20060410|STORE00002|      G00023|      1.0|       0.31|\n",
      "| 20060410|STORE00003|      G00002|      2.0|       2.11|\n",
      "| 20060410|STORE00003|      G00003|      2.0|        2.2|\n",
      "| 20060410|STORE00003|      G00004|     20.0|      23.56|\n",
      "| 20060410|STORE00003|      G00007|     47.0|      67.46|\n",
      "| 20060410|STORE00003|      G00013|      2.0|       1.18|\n",
      "| 20060410|STORE00003|      G00015|      4.0|       5.89|\n",
      "| 20060410|STORE00004|      G00003|      1.0|       3.35|\n",
      "| 20060410|STORE00004|      G00004|      8.0|       8.69|\n",
      "| 20060410|STORE00004|      G00008|      1.0|       0.87|\n",
      "| 20060410|STORE00004|      G00015|      1.0|       0.93|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prod_30_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_40_df = spark.sql(\"SELECT SHOP_DATE, STORE_CODE, PROD_CODE_40, SUM(QUANTITY) AS TOTAL_QTY, ROUND(SUM(SPEND), 2) AS TOTAL_SPEND FROM STORE_DATA GROUP BY SHOP_DATE, STORE_CODE, PROD_CODE_40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:09:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_40, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_40, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:09:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_40, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------+-----------+\n",
      "|SHOP_DATE|STORE_CODE|PROD_CODE_40|TOTAL_QTY|TOTAL_SPEND|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "| 20061219|STORE00027|      D00002|     40.0|      58.04|\n",
      "| 20061218|STORE00030|      D00001|      7.0|       8.51|\n",
      "| 20061221|STORE00065|      D00004|      4.0|       7.92|\n",
      "| 20061218|STORE00327|      D00002|     39.0|      59.88|\n",
      "| 20061222|STORE00327|      D00002|     52.0|      77.29|\n",
      "| 20061219|STORE00337|      D00001|      4.0|       4.88|\n",
      "| 20061223|STORE00352|      D00003|      7.0|       5.06|\n",
      "| 20061218|STORE00377|      D00002|     84.0|     114.26|\n",
      "| 20061224|STORE00377|      D00004|      2.0|       4.18|\n",
      "| 20061219|STORE00468|      D00001|      2.0|       2.25|\n",
      "| 20061218|STORE00500|      D00009|      1.0|       1.35|\n",
      "| 20061223|STORE00508|      D00001|      5.0|       2.16|\n",
      "| 20061224|STORE00560|      D00003|     16.0|       11.8|\n",
      "| 20061219|STORE00574|      D00001|     23.0|      16.83|\n",
      "| 20061223|STORE00611|      D00002|     64.0|      86.44|\n",
      "| 20061224|STORE00616|      D00003|     27.0|      19.29|\n",
      "| 20061220|STORE00625|      D00001|      9.0|       5.01|\n",
      "| 20061224|STORE00667|      D00008|      9.0|       63.0|\n",
      "| 20061224|STORE00673|      D00001|      5.0|       7.55|\n",
      "| 20061218|STORE00704|      D00001|      4.0|        4.3|\n",
      "+---------+----------+------------+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prod_40_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SHOP_DATE: string (nullable = true)\n",
      " |-- STORE_CODE: string (nullable = true)\n",
      " |-- PROD_CODE_40: string (nullable = true)\n",
      " |-- TOTAL_QTY: double (nullable = true)\n",
      " |-- TOTAL_SPEND: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod_40_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the estimated size of each of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_df_memory_usage(df)-> None:\n",
    "    sample = df.sample(fraction=0.01)\n",
    "    pdf = sample.toPandas()\n",
    "    print(pdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:34:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:34:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6057 entries, 0 to 6056\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   SHOP_DATE    6057 non-null   object \n",
      " 1   STORE_CODE   6056 non-null   object \n",
      " 2   TOTAL_QTY    6056 non-null   float64\n",
      " 3   TOTAL_SPEND  6056 non-null   float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 189.4+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(store_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 189.4 kb * 100 = 18.9MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:36:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, STORE_CODE, STORE_FORMAT\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE, STORE_FORMAT\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:36:56 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, STORE_CODE, STORE_FORMAT\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "[Stage 42:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6005 entries, 0 to 6004\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SHOP_DATE     6005 non-null   object \n",
      " 1   STORE_CODE    6004 non-null   object \n",
      " 2   STORE_FORMAT  6004 non-null   object \n",
      " 3   TOTAL_QTY     6004 non-null   float64\n",
      " 4   TOTAL_SPEND   6004 non-null   float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 234.7+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(store_format_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 235kb * 100 = 23.5MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:39:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_10, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_10, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:39:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_10, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 212111 entries, 0 to 212110\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   SHOP_DATE     212111 non-null  object \n",
      " 1   STORE_CODE    212109 non-null  object \n",
      " 2   PROD_CODE_10  212109 non-null  object \n",
      " 3   TOTAL_QTY     212109 non-null  float64\n",
      " 4   TOTAL_SPEND   212109 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 8.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(prod_10_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 8.1MB * 100 = 810MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:42:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_20, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_20, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:42:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_20, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136880 entries, 0 to 136879\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   SHOP_DATE     136880 non-null  object \n",
      " 1   STORE_CODE    136879 non-null  object \n",
      " 2   PROD_CODE_20  136879 non-null  object \n",
      " 3   TOTAL_QTY     136879 non-null  float64\n",
      " 4   TOTAL_SPEND   136879 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(prod_20_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 5.2MB * 100 = 520MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:44:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_30, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_30, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:44:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_30, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77700 entries, 0 to 77699\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SHOP_DATE     77700 non-null  object \n",
      " 1   STORE_CODE    77698 non-null  object \n",
      " 2   PROD_CODE_30  77698 non-null  object \n",
      " 3   TOTAL_QTY     77698 non-null  float64\n",
      " 4   TOTAL_SPEND   77698 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 3.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(prod_30_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 3MB * 100 = 300MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/12 07:31:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: SHOP_DATE, QUANTITY, SFNND, PROD_CODE_40, STORE_CODE\n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_40, STORE_CODE\n",
      "Expected: SPEND but found: SFNND\n",
      "CSV file: hdfs://localhost:9000/transactions/transactions_200607.csv\n",
      "23/09/12 07:31:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: date_from, , , , \n",
      " Schema: SHOP_DATE, QUANTITY, SPEND, PROD_CODE_40, STORE_CODE\n",
      "Expected: SHOP_DATE but found: date_from\n",
      "CSV file: hdfs://localhost:9000/transactions/time.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28393 entries, 0 to 28392\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SHOP_DATE     28393 non-null  object \n",
      " 1   STORE_CODE    28393 non-null  object \n",
      " 2   PROD_CODE_40  28393 non-null  object \n",
      " 3   TOTAL_QTY     28393 non-null  float64\n",
      " 4   TOTAL_SPEND   28393 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "estimate_df_memory_usage(prod_40_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated df size = 1.1MB * 100 = 110MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore EDA capabilities of pyspark - is it better to use pandas on the data directly?\n",
    "### How useful is spark for feature engineering vs python?\n",
    "### Is it better to build NN in spark (does spark support keras/tensorflow) or in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
